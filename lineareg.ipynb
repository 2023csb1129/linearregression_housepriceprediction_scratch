
# ===========================
# House Price Prediction using Single Feature (Size)
# Linear Regression From Scratch
# ===========================

import numpy as np
import matplotlib.pyplot as plt

# ---------------------------
# Step 1: Define example data
# ---------------------------
# Sizes of houses in square feet
sizes = np.array([500, 750, 1000, 1250, 1500, 1750, 2000])

# Corresponding house prices in $1000s
prices = np.array([150, 200, 250, 300, 350, 400, 450])

# Number of training examples
num_examples = len(prices)

# ----------------------------------------
# Step 2: Normalize the feature (important)
# ----------------------------------------
# This helps gradient descent converge faster and avoid large updates
mean_size = np.mean(sizes)
std_size = np.std(sizes)
sizes_normalized = (sizes - mean_size) / std_size

# Add a column of ones to include the bias (intercept) term
X = np.c_[np.ones((num_examples, 1)), sizes_normalized]

# --------------------------------------
# Step 3: Initialize model parameters
# --------------------------------------
# We start with both parameters set to zero
params = np.zeros(2)

# --------------------------------------
# Step 4: Define the cost function
# --------------------------------------
def compute_mse(X, y, params):
    """
    Compute Mean Squared Error cost function.

    Parameters:
    X : Feature matrix
    y : Target values
    params : Model parameters (weights)

    Returns:
    cost : Scalar cost value
    """
    predictions = X.dot(params)
    errors = predictions - y
    cost = (1 / (2 * len(y))) * np.sum(errors ** 2)
    return cost

# --------------------------------------
# Step 5: Implement Gradient Descent
# --------------------------------------
learning_rate = 0.1    # Controls step size
iterations = 1000      # Number of iterations to run
cost_history = []      # To track cost over time

for i in range(iterations):
    # Compute predictions using current parameters
    preds = X.dot(params)

    # Compute the error
    errors = preds - prices

    # Calculate gradient
    gradients = (1 / num_examples) * X.T.dot(errors)

    # Update parameters
    params = params - learning_rate * gradients

    # Save the cost for plotting
    current_cost = compute_mse(X, prices, params)
    cost_history.append(current_cost)

# Print final parameters
print(f"Final parameters: bias (theta_0) = {params[0]:.2f}, weight (theta_1) = {params[1]:.2f}")

# --------------------------------------
# Step 6: Plot cost over iterations
# --------------------------------------
plt.plot(range(iterations), cost_history, color='green')
plt.xlabel("Iterations")
plt.ylabel("Cost (MSE)")
plt.title("Cost Function Convergence")
plt.grid(True)
plt.show()

# --------------------------------------
# Step 7: Visualize the regression line
# --------------------------------------
# Plot the original data
plt.scatter(sizes, prices, color='purple', label='Training Data')

# Create a smooth line of sizes for plotting regression line
sizes_line = np.linspace(min(sizes), max(sizes), 100)
sizes_line_norm = (sizes_line - mean_size) / std_size

# Compute predicted prices using learned parameters
predicted_prices = params[0] + params[1] * sizes_line_norm

# Plot the regression line
plt.plot(sizes_line, predicted_prices, color='orange', label='Regression Line')
plt.xlabel("Size (sqft)")
plt.ylabel("Price ($1000s)")
plt.title("House Size vs Price")
plt.legend()
plt.grid(True)
plt.show()

# --------------------------------------
# Step 8: Define a prediction function
# --------------------------------------
def predict_price(size_input):
    """
    Predict house price given the size (sqft).

    Parameters:
    size_input : Size of the house in sqft

    Returns:
    Predicted price in $1000s
    """
    size_norm = (size_input - mean_size) / std_size
    price = params[0] + params[1] * size_norm
    return price

# Example prediction
example_size = 1800
predicted_price = predict_price(example_size)
print(f"Predicted price for {example_size} sqft house: ${predicted_price * 1000:.2f}")
